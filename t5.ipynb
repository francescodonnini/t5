{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "from numpy.ma.core import asarray\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "data_path = '/content/drive/MyDrive/chest_xray/'"
   ],
   "metadata": {
    "id": "kREINtnbvDEo",
    "outputId": "d50061be-462f-4f5f-c233-3884d734c05d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "kREINtnbvDEo",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "id": "8929e246a71dae25",
    "ExecuteTime": {
     "end_time": "2025-01-26T19:13:37.059485Z",
     "start_time": "2025-01-26T19:13:37.055633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = 'data/chest_xray'"
   ],
   "id": "8929e246a71dae25",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "id": "1fde9c4310d479cd"
   },
   "cell_type": "markdown",
   "source": [
    "Sto considerando di usare i seguenti modelli di ML:\n",
    "1. ResNet.\n",
    "2. GoogLeNet.\n",
    "3. AlexNet."
   ],
   "id": "1fde9c4310d479cd"
  },
  {
   "metadata": {
    "id": "2f4f765f8bac3d3",
    "outputId": "87deb04b-abb9-47d4-d1ba-4a0cf0e17e0d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-01-26T19:00:20.474580Z",
     "start_time": "2025-01-26T19:00:20.307323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path(os.path.join(data_path, 'train'))\n",
    "total = len(list(data_dir.glob('**/*.jpeg')))\n",
    "bacteria = len(list(data_dir.glob('**/BACTERIA-*.jpeg')))\n",
    "virus = len(list(data_dir.glob('**/VIRUS-*.jpeg')))\n",
    "P = len(list(data_dir.glob('**/NORMAL-*.jpeg')))\n",
    "N = total - P\n",
    "print(f'#training set = {total}')\n",
    "print(f'#positives = {P}')\n",
    "print(f'#negatives = {N} (bacteria = {bacteria}, virus = {virus})')"
   ],
   "id": "2f4f765f8bac3d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#training set = 5232\n",
      "#positives = 1349\n",
      "#negatives = 3883 (bacteria = 2538, virus = 1345)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "import keras\n",
    "\n",
    "# see: https://keras.io/api/data_loading/image/#image_dataset_from_directory-function\n",
    "(training, validation) = keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    color_mode='grayscale',\n",
    "    image_size=(224, 224),\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='both'\n",
    ")"
   ],
   "metadata": {
    "id": "zGXqtE1izH-7",
    "outputId": "7b1193c7-23ce-4021-a395-701160b69429",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-01-26T19:13:42.511790Z",
     "start_time": "2025-01-26T19:13:42.285194Z"
    }
   },
   "id": "zGXqtE1izH-7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5232 files belonging to 2 classes.\n",
      "Using 4186 files for training.\n",
      "Using 1046 files for validation.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T19:14:20.405418Z",
     "start_time": "2025-01-26T19:14:20.399698Z"
    }
   },
   "cell_type": "code",
   "source": "help(training.batch)",
   "id": "d95de1361ba02a1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method batch in module tensorflow.python.data.ops.dataset_ops:\n",
      "\n",
      "batch(batch_size, drop_remainder=False, num_parallel_calls=None, deterministic=None, name=None) -> 'DatasetV2' method of tensorflow.python.data.ops.prefetch_op._PrefetchDataset instance\n",
      "    Combines consecutive elements of this dataset into batches.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(8)\n",
      "    >>> dataset = dataset.batch(3)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(8)\n",
      "    >>> dataset = dataset.batch(3, drop_remainder=True)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [array([0, 1, 2]), array([3, 4, 5])]\n",
      "\n",
      "    The components of the resulting element will have an additional outer\n",
      "    dimension, which will be `batch_size` (or `N % batch_size` for the last\n",
      "    element if `batch_size` does not divide the number of input elements `N`\n",
      "    evenly and `drop_remainder` is `False`). If your program depends on the\n",
      "    batches having the same outer dimension, you should set the `drop_remainder`\n",
      "    argument to `True` to prevent the smaller batch from being produced.\n",
      "\n",
      "    Note: If your program requires data to have a statically known shape (e.g.,\n",
      "    when using XLA), you should use `drop_remainder=True`. Without\n",
      "    `drop_remainder=True` the shape of the output dataset will have an unknown\n",
      "    leading dimension due to the possibility of a smaller final batch.\n",
      "\n",
      "    Args:\n",
      "      batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      "        consecutive elements of this dataset to combine in a single batch.\n",
      "      drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      "        whether the last batch should be dropped in the case it has fewer than\n",
      "        `batch_size` elements; the default behavior is not to drop the smaller\n",
      "        batch.\n",
      "      num_parallel_calls: (Optional.) A `tf.int64` scalar `tf.Tensor`,\n",
      "        representing the number of batches to compute asynchronously in\n",
      "        parallel.\n",
      "        If not specified, batches will be computed sequentially. If the value\n",
      "        `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      "        calls is set dynamically based on available resources.\n",
      "      deterministic: (Optional.) When `num_parallel_calls` is specified, if this\n",
      "        boolean is specified (`True` or `False`), it controls the order in which\n",
      "        the transformation produces elements. If set to `False`, the\n",
      "        transformation is allowed to yield elements out of order to trade\n",
      "        determinism for performance. If not specified, the\n",
      "        `tf.data.Options.deterministic` option (`True` by default) controls the\n",
      "        behavior.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      A new `Dataset` with the transformation applied as described above.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T19:15:46.361925Z",
     "start_time": "2025-01-26T19:15:46.337384Z"
    }
   },
   "cell_type": "code",
   "source": "batch = training.batch(100)",
   "id": "f17056ad991a1ebd",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T19:17:03.534331Z",
     "start_time": "2025-01-26T19:17:01.761843Z"
    }
   },
   "cell_type": "code",
   "source": "numpy = list(batch.as_numpy_iterator())",
   "id": "42b32949847dcad5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 20:17:03.055443: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 642252800 exceeds 10% of free system memory.\n",
      "2025-01-26 20:17:03.154102: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 642265600 bytes after encountering the first element of size 642265600 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2025-01-26 20:17:03.385702: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 199098368 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [32,224,224,1] and element 30 had shape [26,224,224,1]. [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m numpy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_numpy_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:4738\u001B[0m, in \u001B[0;36mNumpyIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   4735\u001B[0m     numpy\u001B[38;5;241m.\u001B[39msetflags(write\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   4736\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m numpy\n\u001B[0;32m-> 4738\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m nest\u001B[38;5;241m.\u001B[39mmap_structure(to_numpy, \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:826\u001B[0m, in \u001B[0;36mOwnedIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    825\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 826\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    827\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOutOfRangeError:\n\u001B[1;32m    828\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:776\u001B[0m, in \u001B[0;36mOwnedIterator._next_internal\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    773\u001B[0m \u001B[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001B[39;00m\n\u001B[1;32m    774\u001B[0m \u001B[38;5;66;03m# to communicate that there is no more data to iterate over.\u001B[39;00m\n\u001B[1;32m    775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecution_mode(context\u001B[38;5;241m.\u001B[39mSYNC):\n\u001B[0;32m--> 776\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterator_get_next\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    777\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    778\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    779\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_shapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    781\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    782\u001B[0m     \u001B[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001B[39;00m\n\u001B[1;32m    783\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_element_spec\u001B[38;5;241m.\u001B[39m_from_compatible_tensor_list(ret)  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3086\u001B[0m, in \u001B[0;36miterator_get_next\u001B[0;34m(iterator, output_types, output_shapes, name)\u001B[0m\n\u001B[1;32m   3084\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m   3085\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 3086\u001B[0m   \u001B[43m_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from_not_ok_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3087\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_FallbackException:\n\u001B[1;32m   3088\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:5983\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   5981\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NoReturn:\n\u001B[1;32m   5982\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m-> 5983\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [32,224,224,1] and element 30 had shape [26,224,224,1]. [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "id": "8543b0ed6566af0f"
   },
   "cell_type": "markdown",
   "source": [
    "Le immagini nel training set sono 5232 di cui: 1349 appartenenti alla classe NORMAL mentre 3883 alla classe PNEUMONIA.\n",
    "\n",
    "```py\n",
    "#training set = 5232\n",
    "#positives = 1349\n",
    "#negatives = 3883 (bacteria = 2538, virus = 1345)\n",
    "```\n",
    "\n",
    "Sto considerando diverse strategie per aumentare la dimensione del dataset:\n",
    "1. Trasformazioni geometriche: specchiare, ruotare, tagliare, allungare.\n",
    "   a. Specchiare e ruotare non mi sembrano che possano essere molto utili per questa tipologia di problema. Similmente anche\n",
    "      il ritagliare l'immagine potrebbe rimuovere porzioni di immagini che potrebbero rivelarsi fondamentali per individuare o meno\n",
    "      la polmonite.\n",
    "   b. Tag\n",
    "2. Modificare la luminosità."
   ],
   "id": "8543b0ed6566af0f"
  },
  {
   "metadata": {
    "id": "3748e3cdf41bd58b"
   },
   "cell_type": "markdown",
   "source": [
    "È necessario ridimensionare le immagini per:\n",
    "- Utilizzare meno risorse computazionali.\n",
    "- Velocizzare sia addestramento che inferenza.\n",
    "Al momento sto considerando le diverse strategie per il ridimensionamento delle immagini:\n",
    "1. Ridimensionare tutte le immagini a 133x133 dove 133 è l'altezza minima tra tutte le immagini.\n",
    "2. Ridimensionare tutte le immagini a 290x290 dove 290 è l'altezza media delle immagini"
   ],
   "id": "3748e3cdf41bd58b"
  },
  {
   "cell_type": "code",
   "source": [
    "from keras import activations, layers, models\n",
    "from typing import Tuple, Callable\n",
    "\n",
    "\n",
    "class ResBlock(layers.Layer):\n",
    "    def __init__(self, k: Tuple[int, int], n: int, s: Tuple[int, int], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv1 = layers.Conv2D(n, k, s)\n",
    "        self.bn1   = layers.BatchNormalization()\n",
    "        self.conv2 = layers.Conv2D(n, k, s)\n",
    "        self.bn2   = layers.BatchNormalization()\n",
    "        self.sum   = layers.Add()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        z = self.conv1(x)\n",
    "        z = self.bn1(z)\n",
    "        z = activations.leaky_relu(z, 0.2)\n",
    "        z = self.conv2(z)\n",
    "        z = self.bn2(z)\n",
    "        return self.sum(x, z)\n",
    "\n",
    "\n",
    "class Resizer(layers.Layer):\n",
    "    def __init__(self, target: Tuple[int, int], interpolation='bilinear', r: int=4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        ## learnable layers\n",
    "        self.conv1 = layers.Conv2D(16, (7, 7), activation=activations.leaky_relu)\n",
    "        self.conv2 = layers.Conv2D(16, (1, 1), activation=activations.leaky_relu)\n",
    "        self.bn1   = layers.BatchNormalization()\n",
    "        self.r_blocks = [ResBlock((3, 3), 16, (1, 1)) for _ in range(r)]\n",
    "        self.conv3 = layers.Conv2D(16, (3, 3), (1, 1))\n",
    "        self.bn2   = layers.BatchNormalization()\n",
    "        self.conv4 = layers.Conv2D(3, (7, 7), (1, 1))\n",
    "        ## non-learnable layers\n",
    "        self.sum  = layers.Add()\n",
    "        self.sampler = layers.UpSampling2D(target, interpolation=interpolation)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.conv2(y)\n",
    "        y = self.bn1(y)\n",
    "        y = self.sampler(y)\n",
    "        z = y\n",
    "        for r_block in self.r_blocks:\n",
    "            z = r_block(z)\n",
    "        z = self.conv3(z)\n",
    "        z = self.bn2(z)\n",
    "        z = self.sum(y, z)\n",
    "        z = self.conv4(z)\n",
    "        x = self.sampler(x)\n",
    "        return self.sum(x, z)\n"
   ],
   "metadata": {
    "id": "kEBld5tDxk55",
    "ExecuteTime": {
     "end_time": "2025-01-21T15:46:51.783501Z",
     "start_time": "2025-01-21T15:46:48.679598Z"
    }
   },
   "id": "kEBld5tDxk55",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 16:46:49.252417: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-21 16:46:49.272130: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-21 16:46:49.278932: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-21 16:46:49.338871: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "from keras import activations, layers, models\n",
    "\n",
    "\n",
    "def alex_net():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(96, (11, 11), (4, 4),\n",
    "                      activation=activations.relu),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPool2D((3, 3), (2, 2)),\n",
    "        layers.Conv2D(256, (5, 5), (2, 2), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPool2D((3, 3), (2, 2)),\n",
    "        layers.Conv2D(384, (3, 3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(384, (3, 3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPool2D((3, 3), (2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(4096),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(2, activation=activations.softmax)\n",
    "    ])\n",
    "    return model"
   ],
   "metadata": {
    "id": "847SH82ZxqXY",
    "ExecuteTime": {
     "end_time": "2025-01-21T15:46:56.418825Z",
     "start_time": "2025-01-21T15:46:56.411750Z"
    }
   },
   "id": "847SH82ZxqXY",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "from keras import callbacks\n",
    "\n",
    "model = alex_net()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "id": "8ZOP4BZox3fm"
   },
   "id": "8ZOP4BZox3fm",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "hist = model.fit(training, epochs=30, validation_data=validation, callbacks=[callbacks.EarlyStopping(patience=10)])"
   ],
   "metadata": {
    "id": "u43vb1UtyVPc",
    "outputId": "ea292bfb-3a16-4ed7-fde2-1814bcc34076",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "u43vb1UtyVPc",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m  8/131\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m28:04\u001B[0m 14s/step - accuracy: 0.5177 - loss: 61.4990"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
