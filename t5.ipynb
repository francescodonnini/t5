{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/MyDrive/chest_xray/'"
      ],
      "metadata": {
        "id": "kREINtnbvDEo",
        "outputId": "9a4c5d97-b2fe-4067-9392-b7fff6a2f9a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kREINtnbvDEo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8929e246a71dae25"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "data_path = 'data/chest_xray'"
      ],
      "id": "8929e246a71dae25"
    },
    {
      "metadata": {
        "id": "1fde9c4310d479cd"
      },
      "cell_type": "markdown",
      "source": [
        "Sto considerando di usare i seguenti modelli di ML:\n",
        "1. ResNet.\n",
        "2. GoogLeNet.\n",
        "3. AlexNet."
      ],
      "id": "1fde9c4310d479cd"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-21T11:53:06.395232Z",
          "start_time": "2025-01-21T11:53:06.358296Z"
        },
        "id": "2f4f765f8bac3d3",
        "outputId": "a61bf04e-5b0e-4d7e-cf07-9dc539b30bb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "data_dir = pathlib.Path(os.path.join(data_path, 'train'))\n",
        "total = len(list(data_dir.glob('**/*.jpeg')))\n",
        "bacteria = len(list(data_dir.glob('**/BACTERIA-*.jpeg')))\n",
        "virus = len(list(data_dir.glob('**/VIRUS-*.jpeg')))\n",
        "P = len(list(data_dir.glob('**/NORMAL-*.jpeg')))\n",
        "N = total - P\n",
        "print(f'#training set = {total}')\n",
        "print(f'#positives = {P}')\n",
        "print(f'#negatives = {N} (bacteria = {bacteria}, virus = {virus})')"
      ],
      "id": "2f4f765f8bac3d3",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#training set = 5232\n",
            "#positives = 1349\n",
            "#negatives = 3883 (bacteria = 2538, virus = 1345)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "training_set = utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "zGXqtE1izH-7"
      },
      "id": "zGXqtE1izH-7",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8543b0ed6566af0f"
      },
      "cell_type": "markdown",
      "source": [
        "Le immagini nel training set sono 5232 di cui: 1349 appartenenti alla classe NORMAL mentre 3883 alla classe PNEUMONIA.\n",
        "\n",
        "```py\n",
        "#training set = 5232\n",
        "#positives = 1349\n",
        "#negatives = 3883 (bacteria = 2538, virus = 1345)\n",
        "```\n",
        "\n",
        "Sto considerando diverse strategie per aumentare la dimensione del dataset:\n",
        "1. Trasformazioni geometriche: specchiare, ruotare, tagliare, allungare.\n",
        "   a. Specchiare e ruotare non mi sembrano che possano essere molto utili per questa tipologia di problema. Similmente anche\n",
        "      il ritagliare l'immagine potrebbe rimuovere porzioni di immagini che potrebbero rivelarsi fondamentali per individuare o meno\n",
        "      la polmonite.\n",
        "   b. Tag\n",
        "2. Modificare la luminosità."
      ],
      "id": "8543b0ed6566af0f"
    },
    {
      "metadata": {
        "id": "3748e3cdf41bd58b"
      },
      "cell_type": "markdown",
      "source": [
        "È necessario ridimensionare le immagini per:\n",
        "- Utilizzare meno risorse computazionali.\n",
        "- Velocizzare sia addestramento che inferenza.\n",
        "Al momento sto considerando le diverse strategie per il ridimensionamento delle immagini:\n",
        "1. Ridimensionare tutte le immagini a 133x133 dove 133 è l'altezza minima tra tutte le immagini.\n",
        "2. Ridimensionare tutte le immagini a 290x290 dove 290 è l'altezza media delle immagini"
      ],
      "id": "3748e3cdf41bd58b"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import activations, layers, models\n",
        "\n",
        "class ResBlock(layers.Layer):\n",
        "    def __init__(self, k: (int, int), n: int, s: (int, int), **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv1 = layers.Conv2D(n, k, s)\n",
        "        self.bn1   = layers.BatchNormalization()\n",
        "        self.conv2 = layers.Conv2D(n, k, s)\n",
        "        self.bn2   = layers.BatchNormalization()\n",
        "        self.sum   = layers.Add()\n",
        "\n",
        "    def __call__(self, x):\n",
        "        z = self.conv1(x)\n",
        "        z = self.bn1(z)\n",
        "        z = activations.leaky_relu(z, 0.2)\n",
        "        z = self.conv2(z)\n",
        "        z = self.bn2(z)\n",
        "        return self.sum(x, z)\n",
        "\n",
        "\n",
        "class Resizer(layers.Layer):\n",
        "    def __init__(self, target: (int, int), interpolation='bilinear', r: int=4, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        ## learnable layers\n",
        "        self.conv1 = layers.Conv2D(16, (7, 7), activation=activations.leaky_relu)\n",
        "        self.conv2 = layers.Conv2D(16, (1, 1), activation=activations.leaky_relu)\n",
        "        self.bn1   = layers.BatchNormalization()\n",
        "        self.r_blocks = [ResBlock((3, 3), 16, (1, 1)) for _ in range(r)]\n",
        "        self.conv3 = layers.Conv2D(16, (3, 3), (1, 1))\n",
        "        self.bn2   = layers.BatchNormalization()\n",
        "        self.conv4 = layers.Conv2D(3, (7, 7), (1, 1))\n",
        "        ## non-learnable layers\n",
        "        self.sum  = layers.Add()\n",
        "        self.sampler = layers.UpSampling2D(target, interpolation=interpolation)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = self.conv2(y)\n",
        "        y = self.bn1(y)\n",
        "        y = self.sampler(y)\n",
        "        z = y\n",
        "        for r_block in self.r_blocks:\n",
        "            z = r_block(z)\n",
        "        z = self.conv3(z)\n",
        "        z = self.bn2(z)\n",
        "        z = self.sum(y, z)\n",
        "        z = self.conv4(z)\n",
        "        x = self.sampler(x)\n",
        "        return self.sum(x, z)\n"
      ],
      "metadata": {
        "id": "kEBld5tDxk55"
      },
      "id": "kEBld5tDxk55",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import activations, layers, models\n",
        "\n",
        "\n",
        "def alex_net(resizer: layers.Layer):\n",
        "    model = models.Sequential([\n",
        "        resizer,\n",
        "        layers.Conv2D(96, (11, 11), (4, 4),\n",
        "                      activation=activations.relu),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPool2D((3, 3), (2, 2)),\n",
        "        layers.Conv2D(256, (5, 5), (2, 2), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPool2D((3, 3), (2, 2)),\n",
        "        layers.Conv2D(384, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(384, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(256, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPool2D((3, 3), (2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(4096),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(4096),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(2, activation=activations.softmax)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "847SH82ZxqXY"
      },
      "id": "847SH82ZxqXY",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resizer = Resizer((224, 244))\n",
        "model = alex_net(resizer)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8ZOP4BZox3fm"
      },
      "id": "8ZOP4BZox3fm",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit()"
      ],
      "metadata": {
        "id": "u43vb1UtyVPc"
      },
      "id": "u43vb1UtyVPc",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}